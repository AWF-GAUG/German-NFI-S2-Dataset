{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed315f0-dedc-4671-afea-691adee59326",
   "metadata": {},
   "source": [
    "# Introduction to the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f378af",
   "metadata": {},
   "source": [
    "This is an introduction to the Sentinel-2 German national forest inventory dataset generated in in the frame of the Klimba project by Max Freudenberg, Sebastian Schnell and Paul Magdon.\n",
    "\n",
    "The dataset contains the bottom of atmosphere reflectance values for the majority of the trees in the 2012 German national forest inventory.\n",
    "\n",
    "For questions please refer to: maximilian.freudenberg@uni-goettingen.de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402e0ad-e00c-4b09-8d19-7b99578282a1",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c30c5-9537-4982-af44-cc2658387d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548dc5e-3f36-416d-874e-d46cbe86bb1b",
   "metadata": {},
   "source": [
    "The dataset comes in the form of an sqlite file. We first create an sqlite connection and tell sqlite to return strings as byte-arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5507036-99b5-470c-9188-9f3e8aee6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this path to point to the database file\n",
    "dataset_path = \"/home/max/dr/extract_sentinel_pixels/datasets/S2GNFI_V1_randtime.sqlite\"\n",
    "conn = sqlite3.connect(dataset_path)\n",
    "conn.text_factory = bytes  # this makes sqlite return strings as bytes that we can parse via numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156ec97-0400-4111-9ca8-d2f879c4f908",
   "metadata": {},
   "source": [
    "To load the entire dataset, you need ~30 GB of RAM. But thanks to sqlite we can limit loading to a subset just to inspect a subset of the \n",
    "data. The data is stored in the sqlite table \"data\".\n",
    "\n",
    "For demo purposes, we restrict loading to the classes spruce (10) and beech (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c484775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM data WHERE \\\n",
    "                       (species=10 or species=100) and present_2022=TRUE and dbh_mm>200 and height_dm>120 \\\n",
    "                       order by random() limit 100000\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a1bed-70b3-4d07-8f6e-6e100ccb69c9",
   "metadata": {},
   "source": [
    "The bottom of atmosphere (BOA) reflectances still look strange! That's because they are displayed as raw byte characters. We can easily convert the 20 byte values to 10 16 bit signed integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e47da8-3c4f-4c9a-83ce-540e6c57877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boa = [np.frombuffer(x, dtype=np.int16) for x in df.boa]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c21340-ec9f-4025-910a-821346a0bdea",
   "metadata": {},
   "source": [
    "Already looks much better! But what about the time?! Let's convert it from unix time to a human readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d34be-81fa-4363-b66b-95897a8d2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.time = [datetime.date.fromtimestamp(t) for t in df.time]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3d0f1-7998-4ce2-aadf-131742f473ee",
   "metadata": {},
   "source": [
    "## Quality Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38fe86-9305-4702-af62-022c57dc226c",
   "metadata": {},
   "source": [
    "As you might have noticed, there is a QAI column, which stands for quality assurance information. This information is output by the [FORCE](https://force-eo.readthedocs.io/) satellite image processing suite. The different image conditions are encoded bit-wise in a single unsigned 16 bit integer, as documented [here](https://force-eo.readthedocs.io/en/latest/howto/qai.html#quality-bits-in-force).\n",
    "\n",
    "For convenience, here are the different bit-masks in python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cbf66-fbaf-454f-b614-932ed60d90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID        = 0b000000000000000\n",
    "NODATA       = 0b000000000000001\n",
    "CLOUD_BUFFER = 0b000000000000010\n",
    "CLOUD_OPAQUE = 0b000000000000100\n",
    "CLOUD_CIRRUS = 0b000000000000110\n",
    "CLOUD_SHADOW = 0b000000000001000\n",
    "SNOW         = 0b000000000010000\n",
    "WATER        = 0b000000000100000\n",
    "AOD_INT      = 0b000000001000000\n",
    "AOD_HIGH     = 0b000000010000000\n",
    "AOD_FILL     = 0b000000011000000\n",
    "SUBZERO      = 0b000000100000000\n",
    "SATURATION   = 0b000001000000000\n",
    "SUN_LOW      = 0b000010000000000\n",
    "ILLUMIN_LOW  = 0b000100000000000\n",
    "ILLUMIN_POOR = 0b001000000000000\n",
    "ILLUMIN_NONE = 0b001100000000000\n",
    "SLOPED       = 0b010000000000000\n",
    "WVP_NONE     = 0b100000000000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8793c-7a88-4afd-809a-66bac6ba9667",
   "metadata": {},
   "source": [
    "Let's now look at the QAI value of the first record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bbba1-251f-4948-b07c-830ecdb74724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"qai\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1316df6-1315-4fe1-ba99-47cf3d526d53",
   "metadata": {},
   "source": [
    "...and convert this value to binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a422c62-179c-49d4-af37-54740157115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(10240)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db46a93-d146-40cb-ba19-5768c969b0a0",
   "metadata": {},
   "source": [
    "Now we can count the position of the 1, starting from the right - the 1 is in position 14. Comparing this with the table above tells us, that the area is sloped. Let's check that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a5a83-c98a-46b9-b688-4e433d76bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381d26a-6315-4e3e-b59d-399236571149",
   "metadata": {},
   "source": [
    "Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b9a12-38e9-4b2a-8af2-f8963d86f789",
   "metadata": {},
   "source": [
    "Let's perform a simple check: Are there any pixels in our dataset that FORCE detected as water or snow? To do so, we can combine the different bit flags using the \"logical or\" operator \"|\". This compares two values and sets a bit where either a or b has a bit set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9f989-db01-426d-8089-2fa8dbb273af",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = SNOW | WATER\n",
    "my_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84f3fc-08f4-4097-b617-20d0c3e4259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(my_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee1dbb-8526-43ec-b094-45e6eef2ed53",
   "metadata": {},
   "source": [
    "We have now created a value that has two 1s in positions 5 and 6.\n",
    "\n",
    "If we now want to find out whether some of the QAI values matches our filter, we simply have to check whether there is a 1 in the same positions as in our filter. We do this by the \"logical and\" operator \"&\" that sets a bit if the QAI value *and* our filter have a bit set in the same position. Naturally, any bit set to 1 will yield a number larger zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06932d34-9f68-495f-9a62-c269ebd45f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df[\"qai\"] & my_filter) > 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a658f6e-e8b2-4e4e-b6ae-564e52883630",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3ba8d-9731-4f4e-8b9c-604e63c766c6",
   "metadata": {},
   "source": [
    "-> There are 1795 spruce and beech records in the subset that we have loaded where FORCE recognized water or snow. Water of course makes no sense, because the measured trees are on land, but is obvousily possible in winter.\n",
    "\n",
    "Let's now remove all types of cloud and snow from our dataset by comparing each QAI value with a filter by the logical and operator. If the QAI values and the filter have no common bits the resulting value is zero - these are the cloud free records we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9317f3-e6dc-441d-8980-226686eb9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = CLOUD_BUFFER | CLOUD_CIRRUS | CLOUD_OPAQUE | CLOUD_SHADOW | SNOW\n",
    "mask = (df[\"qai\"] & my_filter) == 0\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f996e4e",
   "metadata": {},
   "source": [
    "**Use logical or \"|\" to combine filter values, logical and \"&\" to compare the filter with the QAI flag and check whether the result is zero to include all valid records.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90fee13-4c5b-48ef-9c30-50062b372fc1",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436a323-60a4-4242-916b-a11f91cf352e",
   "metadata": {},
   "source": [
    "Let's plot the time series of our records for beech for the Sentinel-2 band B8. You find an overview of the Sentinel-2 bands [here](https://gisgeography.com/sentinel-2-bands-combinations/).\n",
    "\n",
    "<table><tbody><tr><th>Band</th><th>Resolution</th><th>Central Wavelength</th><th>Description</th></tr><tr><td>B1</td><td>60 m</td><td>443 nm</td><td>Ultra Blue (Coastal and Aerosol)</td></tr><tr><td>B2</td><td>10 m</td><td>490 nm</td><td>Blue</td></tr><tr><td>B3</td><td>10 m</td><td>560 nm</td><td>Green</td></tr><tr><td>B4</td><td>10 m</td><td>665 nm</td><td>Red</td></tr><tr><td>B5</td><td>20 m</td><td>705 nm</td><td>Visible and Near Infrared (VNIR)</td></tr><tr><td>B6</td><td>20 m</td><td>740 nm</td><td>Visible and Near Infrared (VNIR)</td></tr><tr><td>B7</td><td>20 m</td><td>783 nm</td><td>Visible and Near Infrared (VNIR)</td></tr><tr><td>B8</td><td>10 m</td><td>842 nm</td><td>Visible and Near Infrared (VNIR)</td></tr><tr><td>B8a</td><td>20 m</td><td>865 nm</td><td>Visible and Near Infrared (VNIR)</td></tr><tr><td>B9</td><td>60 m</td><td>940 nm</td><td>Short Wave Infrared (SWIR)</td></tr><tr><td>B10</td><td>60 m</td><td>1375 nm</td><td>Short Wave Infrared (SWIR)</td></tr><tr><td>B11</td><td>20 m</td><td>1610 nm</td><td>Short Wave Infrared (SWIR)</td></tr><tr><td>B12</td><td>20 m</td><td>2190 nm</td><td>Short Wave Infrared (SWIR)</td></tr></tbody></table>\n",
    "\n",
    "FORCE uses all bands with 10 or 20 meters resolution. So to get Sentinel band 8 we have to select the band with index 6 in our dataset. (Python indexing starts at 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce4138-edf1-4f3f-895c-1e53acffb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"b8\"] = [boa[6] for boa in df[\"boa\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aae763-5965-4488-9dbf-c9283dcc8f46",
   "metadata": {},
   "source": [
    "Now let's group the values based on the time and species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1382e6-87ee-477e-a2fc-07998a68b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = df[[\"time\", \"species\", \"b8\"]].groupby(\"species\")\n",
    "grouped_df_beech = species_groups.get_group(100).groupby(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13aadd-75d6-4819-96cb-260dfa4a8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_beech.get_group(datetime.date(2022,3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0096a-d80a-4e4e-8801-f6ee803c4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_series = grouped_df_beech.mean()[\"b8\"]\n",
    "averaged_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c5291-cbbc-4d9b-a770-d1f6ccac71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(averaged_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d3740-1ca6-4763-887d-86f045a9e9f7",
   "metadata": {},
   "source": [
    "Oh what is this? There are still negative values! We forgot to filter for NODATA values. While we're at it, let's also remove pixels with high aerosol optical depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bf561-68c1-4cf7-8967-446500c4ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = NODATA | CLOUD_BUFFER | CLOUD_CIRRUS | CLOUD_OPAQUE | CLOUD_SHADOW | SNOW | AOD_HIGH | AOD_FILL | AOD_INT\n",
    "mask = (df[\"qai\"] & my_filter) == 0\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b207f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it again\n",
    "averaged_series = grouped_df_beech.mean()[\"b8\"]\n",
    "plt.plot(averaged_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202efda5-1037-4973-a80e-27de91a18e6c",
   "metadata": {},
   "source": [
    "Some outlier values are still present, so we'll simply remove all values below zero, because negative reflectances are unphysical. Furthermore, we can divide the BOA value by 100 to obtain the BOA reflectance in %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d407b-4120-4b71-9e63-723405180504",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_series = grouped_df_beech.mean().query(\"b8 > 0\")[\"b8\"]\n",
    "averaged_series /= 100\n",
    "plt.plot(averaged_series)\n",
    "plt.title(\"Beeches, Band B8, 842nm\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"BOA Reflectance [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d5ba9",
   "metadata": {},
   "source": [
    "### Comparison between spruce and beech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = NODATA | CLOUD_BUFFER | CLOUD_CIRRUS | CLOUD_OPAQUE | CLOUD_SHADOW | SNOW | AOD_HIGH | AOD_FILL | AOD_INT\n",
    "mask = (df[\"qai\"] & my_filter) == 0\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c97f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = df[[\"time\", \"species\", \"b8\"]].groupby(\"species\")\n",
    "grouped_df_beech  = species_groups.get_group(100).groupby(\"time\")\n",
    "grouped_df_spruce = species_groups.get_group(10).groupby(\"time\")\n",
    "\n",
    "avg_beech = grouped_df_beech.mean().query(\"b8 > 0\")[\"b8\"] / 100\n",
    "avg_spruce = grouped_df_spruce.mean().query(\"b8 > 0\")[\"b8\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ffe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_beech, label=\"Beech\")\n",
    "plt.plot(avg_spruce, label=\"Spruce\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"BOA Reflectance [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dec718",
   "metadata": {},
   "source": [
    "We see that the data is relatively noisy. This is because we have loaded only a subset of the dataset. Loading all the data takes some time but would improve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b2e4e-2d7b-459f-a69a-57a331f0ca5a",
   "metadata": {},
   "source": [
    "## NDVI\n",
    "\n",
    "To explore the data even more, we can take a look at the NDVI. We define the NDVI via the red and near infrared bands (see above table). Python indexing starts at 0 and we skip all bands that have a lower resolution than 20m. We select the 842nm band, because it has 10m resolution, like the red band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acd1f3-98a9-4c45-bace-6a8b044e18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(boa):\n",
    "    boa32 = boa.astype(np.float32)\n",
    "    return (boa32[6] - boa32[3]) / (boa32[6] + boa32[3] + np.float32(1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7ba42-2c2c-4db9-bfe5-5a085ebaf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ndvi\"] = df[\"boa\"].apply(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2842f-badd-4dd6-916b-f4399e12ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a30c1c-6759-4d6d-8c07-9da97df414da",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = NODATA | CLOUD_BUFFER | CLOUD_CIRRUS | CLOUD_OPAQUE | CLOUD_SHADOW | SNOW | AOD_HIGH | AOD_FILL | AOD_INT\n",
    "mask = (df[\"qai\"] & my_filter) == 0\n",
    "df = df[mask]\n",
    "ndvi_beech  = df[[\"time\", \"species\", \"ndvi\"]].query(\"species == 100 and -1 < ndvi < 1\").groupby(\"time\").mean()[\"ndvi\"]\n",
    "ndvi_spruce = df[[\"time\", \"species\", \"ndvi\"]].query(\"species == 10 and -1 < ndvi < 1\").groupby(\"time\").mean()[\"ndvi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d5144-e8d9-4680-baf1-367dca08ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ndvi_beech, label=\"Beech\")\n",
    "plt.plot(ndvi_spruce, label=\"Spruce\")\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"NDVI\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d3213",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There are far more analyses possible with this dataset and we encourage you to try them out! Should you encounter any issues or inconsistencies with the dataset itself, don't hesitate to contact the authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
